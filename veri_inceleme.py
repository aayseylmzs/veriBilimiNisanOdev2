import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('abg_dataset_300.csv')

print("Veri seti boyutu:", df.shape)
print("SÃ¼tunlar:", df.columns.tolist())
print(df.head())

print("\nTanÄ± (Diagnosis) daÄŸÄ±lÄ±mÄ±:")
print(df['Diagnosis'].value_counts()) #Bu daÄŸÄ±lÄ±m, modelimizin sÄ±nÄ±flarÄ± dengeli Ã¶ÄŸrenip Ã¶ÄŸrenemeyeceÄŸini anlamak iÃ§in Ã¶nemlidir

print("Eksik deÄŸer sayÄ±sÄ± (her sÃ¼tun iÃ§in):")
print(df.isnull().sum())

#eksik veri doldurma
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = df.select_dtypes(include=['object']).columns

df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
df[categorical_cols] = df[categorical_cols].fillna('Unknown')

print("\nEksik veri kaldÄ± mÄ±?:", df.isnull().values.any())

le_gender = LabelEncoder()
df['Gender'] = le_gender.fit_transform(df['Gender'])

le_diagnosis = LabelEncoder()
df['Diagnosis_encoded'] = le_diagnosis.fit_transform(df['Diagnosis'])

print("\nTanÄ± KodlarÄ± (Label Encoding):")
for i, label in enumerate(le_diagnosis.classes_):
    print(f"{i} = {label}")

#veri temizliÄŸi
X = df.drop(columns=['Patient ID', 'Sample Time', 'Diagnosis', 'Diagnosis_encoded'])
y = df['Diagnosis_encoded']

#eÄŸitim
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\nEÄŸitim seti boyutu: {X_train.shape}")
print(f"Test seti boyutu: {X_test.shape}")

#modelleme
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("ğŸ” DoÄŸruluk (Accuracy):", accuracy_score(y_test, y_pred))
print("ğŸ¯ F1 Skoru (macro):", f1_score(y_test, y_pred, average='macro'))
print("\nğŸ“‹ SÄ±nÄ±flandÄ±rma Raporu:")
print(classification_report(y_test, y_pred, target_names=le_diagnosis.classes_))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le_diagnosis.classes_, yticklabels=le_diagnosis.classes_, cmap="Blues")
plt.title("ğŸ“Š KarÄ±ÅŸÄ±klÄ±k Matrisi")
plt.xlabel("Tahmin Edilen")
plt.ylabel("GerÃ§ek")
plt.show()

#DoÄŸruluk (Accuracy): 0.62
#Bu oran, modelin genel anlamda %62 doÄŸru tahmin yaptÄ±ÄŸÄ±na iÅŸaret ediyor. Ancak, F1 skoru dÃ¼ÅŸÃ¼k olduÄŸundan, bazÄ± sÄ±nÄ±flarda Ã§ok dÃ¼ÅŸÃ¼k baÅŸarÄ± var. Ã–zellikle "Metabolic Acidosis" ve "Respiratory Alkalosis" gibi az Ã¶rneklemli sÄ±nÄ±flar iÃ§in model doÄŸru tahmin yapamÄ±yor.
#sÄ±nÄ±flar dengesiz olduÄŸundan model Ã§oÄŸunlukla normal olarak tahmin ediyor

# Random Forest modeli
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Ã–zelliklerin Ã¶nemi
feature_importances = rf_model.feature_importances_

# Ã–zellik adlarÄ± ve Ã¶nem dÃ¼zeylerini gÃ¶ster
feature_data = pd.DataFrame({
    'Feature': X.columns,
    'Importance': feature_importances
})

# Ã–nem sÄ±rasÄ±na gÃ¶re sÄ±rala
feature_data = feature_data.sort_values(by='Importance', ascending=False)

print(feature_data)

#NÄ°SAN AYI ODEV 1
#KNN MODELÄ°

knn_model = KNeighborsClassifier(n_neighbors=5)  # k=5 (yakÄ±n 5 komÅŸu)
knn_model.fit(X_train, y_train)
#TAHMÄ°N
y_pred_knn = knn_model.predict(X_test)
#DOÄRULUK SKORU

print("ğŸ” KNN DoÄŸruluk (Accuracy):", accuracy_score(y_test, y_pred_knn))
print("\nğŸ“Š KarÄ±ÅŸÄ±klÄ±k Matrisi:")
cm_knn = confusion_matrix(y_test, y_pred_knn)
plt.figure(figsize=(8,6))
sns.heatmap(cm_knn, annot=True, fmt='d', xticklabels=le_diagnosis.classes_, yticklabels=le_diagnosis.classes_, cmap="Blues")
plt.title("KNN - KarÄ±ÅŸÄ±klÄ±k Matrisi")
plt.xlabel("Tahmin Edilen")
plt.ylabel("GerÃ§ek")
plt.show()

# KNN DoÄŸruluk (Accuracy): 0.5166666666666667

# KNN modelinde farklÄ± k deÄŸerleri ile optimizasyon yapmak
for k in [3, 5, 7, 9, 11]:
    knn_model = KNeighborsClassifier(n_neighbors=k)
    knn_model.fit(X_train, y_train)
    y_pred_knn = knn_model.predict(X_test)
    print(f"\nK = {k} - DoÄŸruluk:", accuracy_score(y_test, y_pred_knn))


